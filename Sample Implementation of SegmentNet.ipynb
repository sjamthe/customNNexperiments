{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample implementation using Segment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment import Segment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_quartic(x):\n",
    "    a = -0.0179516\n",
    "    b = 0.331323\n",
    "    c = -1.63398\n",
    "    d = 1.01107\n",
    "    f = 5.73434\n",
    "    return a*x**4 + b*x**3 + c*x**2 + d*x + f\n",
    "\n",
    "def normalize(x,y):\n",
    "    x_normalized = torch.nn.functional.normalize(x, dim=0)\n",
    "    y_normalized = torch.nn.functional.normalize(y, dim=0)\n",
    "    return x_normalized, y_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250]) torch.Size([250])\n",
      "torch.Size([250, 1]) torch.Size([250, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(-1.5, 11., .05)\n",
    "ytest = f_quartic(x)\n",
    "#normalization - important\n",
    "x, ytest = normalize(x, ytest)\n",
    "print(x.shape, ytest.shape)\n",
    "\n",
    "# Reshape x, ytest to N,1\n",
    "x = x.view(x.shape[0], 1)\n",
    "ytest = ytest.reshape(x.shape[0], 1)\n",
    "print(x.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "\n",
    "model = Segment(x.shape[1], ytest.shape[1], 5)\n",
    "\n",
    "#Initialize model parameters - extremely important.\n",
    "model.custom_init(x.min(dim=0).values, x.max(dim=0).values)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "lr=.0001\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "\n",
    "# create dataset that can be used in a dataloader \n",
    "dataset = torch.utils.data.TensorDataset(x, ytest)\n",
    "batch_size=64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 10 Average loss: 0.0036\n",
      "====> Epoch: 20 Average loss: 0.0033\n",
      "====> Epoch: 30 Average loss: 0.0029\n",
      "====> Epoch: 40 Average loss: 0.0026\n",
      "====> Epoch: 50 Average loss: 0.0023\n",
      "====> Epoch: 60 Average loss: 0.0020\n",
      "====> Epoch: 70 Average loss: 0.0017\n",
      "====> Epoch: 80 Average loss: 0.0015\n",
      "====> Epoch: 90 Average loss: 0.0014\n",
      "====> Epoch: 100 Average loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        # Forward pass\n",
    "        [X, Y] = data\n",
    "        ypred = model(X)\n",
    "        # Calculate the loss\n",
    "        loss = criterion(ypred, Y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if batch_idx % 100 == 0:\n",
    "        #    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #        epoch,\n",
    "        #        batch_idx * len(X),\n",
    "        #        len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
    "        #        loss.item() / len(X)))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(dataloader.dataset)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
